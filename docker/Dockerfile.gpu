# Dockerfile.gpu - Dockerfile for GPU-enabled deployment
FROM nvidia/cuda:12.2.0-runtime-ubuntu22.04

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3 python3-pip python3-venv \
    tesseract-ocr libgl1-mesa-glx poppler-utils \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt ./
RUN pip3 install --upgrade pip && pip3 install -r requirements.txt

# Install FastAPI, Uvicorn, and WebSockets dependencies
RUN pip3 install fastapi uvicorn[standard] websockets

# Install Cloudflared (static binary from Cloudflare)
RUN curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -o /usr/local/bin/cloudflared \
    && chmod +x /usr/local/bin/cloudflared

# Copy the rest of the application
COPY . .

# Set environment variables for CUDA and app config
ENV CUDA_VISIBLE_DEVICES=0 \
    LLM_API_PORT=${LLM_API_PORT:-5001} \
    LLM_PROVIDER=${LLM_PROVIDER:-ollama} \
    MODEL=${MODEL:-hf.co/unsloth/Phi-4-reasoning-plus-GGUF:Q5_K_M} \
    EXTERNAL_RAG=${EXTERNAL_RAG:-false} \
    PURGE_VARIABLES=${PURGE_VARIABLES:-false} \
    SESSION_COOKIE_SECURE="true" \
    APP_ADMIN_USERNAME=${APP_ADMIN_USERNAME:-admin} \
    APP_ADMIN_PASSWORD=${APP_ADMIN_PASSWORD:-admin}

# Expose the GUI port for NGINX/Cloudflare proxy
EXPOSE 3773

# Entrypoint logic: select between GUI and CLI based on APP_MODE (default: gui)
ENV APP_MODE=gui
COPY scripts/cloudflared-entrypoint.sh /app/scripts/cloudflared-entrypoint.sh
RUN chmod +x /app/scripts/cloudflared-entrypoint.sh

ENTRYPOINT ["/app/scripts/cloudflared-entrypoint.sh"]
# The entrypoint script should handle launching either the FastAPI GUI or the CLI pipeline based on $APP_MODE
# Example logic in cloudflared-entrypoint.sh:
#   if [ "$APP_MODE" = "cli" ]; then exec python src/main.py; else exec uvicorn src.modules.gui.app:app --host 0.0.0.0 --port 3773 --workers 4 --proxy-headers --forwarded-allow-ips=*; fi

