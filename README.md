# INTV: Universal Document Analysis & Processing Framework

> **Warning**
> 
> This project is in **alpha** status and is still under active development. Not all features are fully functional or stable. Expect breaking changes, incomplete modules, and evolving APIs. Use at your own risk and see the issues tracker for known limitations.

This project provides a **universal, domain-agnostic framework** for document analysis using Retrieval Augmented Generation (RAG) and LLMs. Unlike traditional systems limited to specific use cases, INTV adapts to **any application domain** through user-defined configurations. The system processes documents, audio, and images to extract structured information and generate outputs tailored to any organizational or analytical requirement.

## üéØ **Universal Application Framework**

INTV is designed as a **configurable processing engine** that can be adapted to any domain:

- **Legal**: Case analysis, affidavits, legal document processing
- **Medical**: Patient records, clinical notes, medical history analysis  
- **Business**: Reports, contracts, meeting transcripts, compliance documents
- **Research**: Academic papers, survey responses, interview transcripts
- **Government**: Policy analysis, citizen feedback, regulatory compliance
- **Education**: Assessments, student records, curriculum analysis
- **Any Domain**: User provides context and policy - system adapts automatically

## Key Philosophy
- **No Hardcoded Assumptions**: System works for any content type or domain
- **User-Defined Purpose**: You specify what to extract and how to structure it
- **Dynamic Configuration**: Runtime adaptation without code changes
- **Universal Fallbacks**: Graceful degradation when configurations are incomplete

---

## üìä **SYSTEM STATUS** (Updated: June 8, 2025)

## üö® **KNOWN ISSUES**

1. **Model Path Organization**: Minor path handling inconsistencies in cache detection
2. **Memory Usage**: Large models require significant RAM (8GB+ recommended for GPU models)
3. **DOCX Dependencies**: Some complex DOCX files may require additional system packages
4. **Web UI**: Partially functional interface needs major fixes and enhancement

## üìà **DEVELOPMENT PRIORITIES**

1. **Short-term**: Complete RAG-to-LLM integration testing and web UI improvements
2. **Medium-term**: Web UI overhaul and multi-user support
3. **Long-term**: API restructuring and advanced AI features
4. **Ongoing**: Performance optimization and cross-platform compatibility

## ‚úÖ **MAJOR MILESTONES COMPLETED** (June 8, 2025)
1. ‚úÖ **Document Processing Pipeline**: Multi-format document extraction with OCR fallback support
2. ‚úÖ **RAG & Semantic Search System**: GPU-accelerated embeddings with sub-second query processing
3. ‚úÖ **Audio Processing Pipeline**: Complete end-to-end audio transcription with live speech capabilities
4. ‚úÖ **Universal Module Creator Framework**: Complete domain-agnostic module creation system
5. ‚úÖ **Automated Installation System**: Cross-platform installer with comprehensive dependency verification

---

## ‚úÖ **WORKING FEATURES**

#### Core Infrastructure
- ‚úÖ **Pipeline Orchestrator**: Unified document/image processing interface
- ‚úÖ **RAG System**: Full implementation with 438MB embedding model
- ‚úÖ **Hardware Detection**: Automatic GPU/CPU tier detection
- ‚úÖ **Model Caching**: Intelligent cache system prevents unnecessary re-downloads
- ‚úÖ **Dependency Management**: Isolated pipx environment with ML dependencies
- ‚úÖ **Configuration System**: YAML-based configuration with runtime loading
- ‚úÖ **Audio Pipeline**: Complete audio processing system with live speech capabilities
- ‚úÖ **Universal Module Creator**: Complete configuration-driven module creation system
- ‚úÖ **Automated Installation System**: Cross-platform installer with dependency verification

#### Universal Module Creator ‚úÖ **FULLY COMPLETED** (June 8, 2025)
- ‚úÖ **Dynamic Module Framework**: Complete configuration-driven module creation system
- ‚úÖ **Domain-Agnostic Processing**: Universal schema implementation for any domain
- ‚úÖ **Runtime Module Creation**: Template-based module generation system
- ‚úÖ **Universal Schema System**: JSON Schema validation with dynamic module configuration
- ‚úÖ **Template Engine**: Complete Jinja2-based template system for dynamic module generation
- ‚úÖ **Module Registry**: Dynamic loading and registration of generated modules
- ‚úÖ **Configuration-Driven Processing**: Complete YAML-based module definition system

#### Document Processing
- ‚úÖ **Text Files**: TXT, DOCX, JSON, TOML, YAML processing
- ‚úÖ **PDF Processing**: Text extraction with OCR fallback
- ‚úÖ **Basic OCR**: Tesseract integration (verified working)
- ‚úÖ **File Type Detection**: Automatic input type classification
- ‚úÖ **Chunking**: Intelligent text chunking for large documents
- ‚úÖ **Unified Interface**: Single `process_document_or_image()` method

#### RAG & Embeddings
- ‚úÖ **Embedding Models**: sentence-transformers integration
- ‚úÖ **Semantic Search**: GPU-accelerated similarity search (99.30 batches/second)
- ‚úÖ **Model Auto-Selection**: Hardware-optimized model selection
- ‚úÖ **Cache Management**: Efficient model storage and retrieval
- ‚úÖ **Local Model Support**: GGUF, safetensors, custom models
- ‚úÖ **Query Processing**: Sub-second query processing for document chunks
- ‚úÖ **Auto Context Detection**: Dynamic token calculation with context window optimization

#### Audio Processing ‚úÖ **FULLY COMPLETED** (June 8, 2025)
- ‚úÖ **Complete Audio Transcription Pipeline**: Enhanced with faster-whisper integration
- ‚úÖ **Advanced Voice Activity Detection**: pyannote/segmentation-3.0 with enhanced filtering
- ‚úÖ **Speaker Diarization**: Complete pyannote/speaker-diarization-3.1 integration
- ‚úÖ **Hardware-Optimized Model Selection**: Auto-detects best models by system capabilities
- ‚úÖ **Configuration-Driven Audio System**: Complete audio config in config.yaml
- ‚úÖ **HuggingFace Token Integration**: .secrets file support for pyannote models
- ‚úÖ **Live Speech Processing System**: Real-time microphone capture with automatic silence detection
- ‚úÖ **Background Processing Architecture**: Threading-based audio processing with callback system
- ‚úÖ **Complete 5-Step Audio Pipeline**: Audio ‚Üí VAD ‚Üí Diarization ‚Üí ASR ‚Üí RAG integration
- ‚úÖ **LiveSpeechProcessor Class**: Continuous microphone processing with silence detection
- ‚úÖ **Dependency Integration**: All pyannote.audio dependencies properly installed via pipx
- ‚úÖ **End-to-End Testing**: Complete audio pipeline verified and operational

#### Automated Installation ‚úÖ **FULLY COMPLETED** (June 8, 2025)
- ‚úÖ **Cross-Platform Installer**: Complete Python-based installer for Windows/Linux/macOS
- ‚úÖ **Dependency Verification**: Comprehensive verification of all Python and native dependencies
- ‚úÖ **Native Package Detection**: System-specific native package installation (tesseract, poppler, ffmpeg)
- ‚úÖ **pipx Environment Management**: Isolated virtual environment with all ML dependencies
- ‚úÖ **Package Manager Integration**: apt, dnf, brew, choco, winget support
- ‚úÖ **Verification System**: Post-installation testing of all 107 packages in pipx environment
- ‚úÖ **Shell Wrapper Scripts**: quick-install.sh and install-dev.sh for streamlined installation
- ‚úÖ **Installation Options**: Dry-run, CPU-only, force-reinstall, skip-native flags supported

## üîß **PARTIALLY WORKING**

#### Document Processing
- üîß **DOCX Processing**: Basic support, needs enhanced dependency handling
- üîß **Image Processing**: Framework exists, needs ML dependency completion
- üîß **Large File Processing**: Works but needs optimization for memory usage

#### Module System
- üîß **Dynamic Module Framework**: Core architecture complete, needs universal schema implementation
- üîß **Configuration-Driven Processing**: Basic support, needs domain-agnostic enhancement
- üîß **Runtime Module Creation**: Framework exists, needs template-based generation


## ‚ùå **NOT WORKING / MISSING**

#### Critical Missing Features
- ‚ùå **Advanced OCR**: Preprocessing, multi-language, quality enhancement
- ‚ùå **Audio Quality Enhancement**: Background noise filtering and audio preprocessing

#### User Interface
- ‚ùå **Web UI**: Partially functional, needs major fixes
- ‚ùå **Interactive CLI**: Basic CLI exists, needs enhancement
- ‚ùå **Real-time Progress**: Limited progress indicators
- ‚ùå **File Upload Interface**: Needs implementation

#### API & Integration
- ‚ùå **API Restructuring**: Endpoints need reorganization
- ‚ùå **External App Support**: Integration framework needs implementation
- ‚ùå **WebSocket Support**: Real-time communication needs work
- ‚ùå **Authentication System**: Security features missing

#### Performance & Scalability
- ‚ùå **Multi-user Support**: Single-user design currently
- ‚ùå **Concurrent Processing**: No job queuing system
- ‚ùå **Resource Management**: Basic resource handling only
- ‚ùå **Performance Optimization**: Large file streaming needed

## üéØ **PERFORMANCE METRICS**

#### RAG System Performance by Hardware Tier

**GPU High-End (RTX 4070 Ti SUPER - gpu_high)** *(Tested)*
- **Model**: 438MB multi-qa-mpnet-base-dot-v1
- **Initialization**: ~26 seconds (cached model)
- **Query Speed**: 0.02-0.21 seconds for 3-5 chunks (GPU accelerated)
- **Processing Rate**: 6-10 chunks/second (GPU optimized)
- **System Memory**: 1.2GB RAM
- **GPU Memory**: 427MB VRAM
- **Auto Context Detection**: ‚úÖ Enabled
- **Token Processing Rate**: 6,619,052 tokens/second
- **Character Processing Rate**: 26,481,579 chars/second
- **Auto Max Tokens**: Dynamic calculation based on context window
- **Context Utilization**: Optimal (auto-calculated per prompt)
- **Memory Efficiency**: Enhanced with auto token management

**CPU-Only Systems (Intel I9-14900K - cpu_medium)** *(Tested)*
- **Model**: Same 438MB model (no auto-downscaling detected)
- **Initialization**: ~26 seconds (cached model, CPU mode)
- **Query Speed**: 0.3-2.5 seconds for 3-5 chunks
- **Processing Rate**: 6-15 chunks/second
- **Memory Usage**: 2.8GB RAM (CPU processing)
- **Auto Context Detection**: ‚úÖ Enabled
- **Token Processing Rate**: 7,096,060 tokens/second
- **Character Processing Rate**: 28,389,997 chars/second
- **Auto Max Tokens**: Dynamic calculation based on context window
- **Context Utilization**: Optimal (auto-calculated per prompt)
- **Memory Efficiency**: Enhanced with auto token management

**Raspberry Pi / ARM Systems (cpu_low)**
- **Model**: Minimal embedding models (50-150MB)
- **Initialization**: 2-5 minutes (first run)
- **Query Speed**: 5-15 seconds for 5 chunks
- **Embedding Speed**: 1-3 batches/second
- **Memory Usage**: 1-2GB RAM
- **Storage**: 500MB+ for minimal models

#### Auto Context Detection Performance *(New Feature)*

**Real-World Document Processing Test Results:**

**GPU High-End (RTX 4070 Ti SUPER):**
- **Documents Processed**: 2 test documents
- **Total Content**: 9,862 characters  
- **Estimated Tokens**: 2,465 tokens
- **Processing Time**: 0.00 seconds (sub-millisecond)
- **Token Processing Rate**: 6,627,538 tokens/second
- **Character Processing Rate**: 26,515,530 chars/second

**CPU-Only (Intel I9-14900K):**
- **Documents Processed**: 2 test documents
- **Total Content**: 9,862 characters  
- **Estimated Tokens**: 2,465 tokens
- **Processing Time**: 0.00 seconds (sub-millisecond)
- **Token Processing Rate**: 7,096,060 tokens/second
- **Character Processing Rate**: 28,389,997 chars/second

**Token Calculation Accuracy**: High precision with dynamic context window sizing

**Key Benefits**: 
- Automatic token limit optimization per LLM model
- Prevents context overflow errors
- Maximizes context utilization efficiency
- Eliminates manual token counting requirements
- Consistent performance across GPU and CPU hardware

## System Requirements by Deployment Type

**High-Performance (Desktop/Server)**
- **RAM**: 8GB+ recommended for GPU models
- **Storage**: 2GB+ for models and cache
- **GPU**: NVIDIA RTX series recommended
- **CPU**: Multi-core Intel/AMD for CPU fallback

**Minimal (Raspberry Pi/ARM)**
- **RAM**: 2GB+ (4GB+ recommended for Pi 4)
- **Storage**: 500MB+ for minimal models
- **CPU**: ARM Cortex-A72+ (Pi 4 or newer)
- **GPU**: Not required, CPU-only processing
- **Note**: Automatic model downscaling for ARM compatibility


---

## üì¶ Installation

INTV uses a comprehensive dependency system with optional feature groups for different deployment scenarios. We provide **automated installation scripts** that handle both pipx package installation and native system dependencies.

### üöÄ Installation Methods

#### For End Users (When Package is Published)

**One-Command Installation:**
```sh
# Linux/macOS
curl -sSL https://raw.githubusercontent.com/Erebus-Nyx/Intv_App/main/quick-install.sh | bash

# Or download and run locally
git clone https://github.com/Erebus-Nyx/Intv_App.git
cd Intv_App
./quick-install.sh
```

**Windows:**
```cmd
# Download and run the batch script
curl -o quick-install.bat https://raw.githubusercontent.com/Erebus-Nyx/Intv_App/main/quick-install.bat
quick-install.bat

# Or from local directory
git clone https://github.com/Erebus-Nyx/Intv_App.git
cd Intv_App
quick-install.bat
```

#### For Developers (Local Installation)

**Development Installation from Source:**
```sh
# Clone the repository
git clone https://github.com/Erebus-Nyx/Intv_App.git
cd Intv_App

# Install for development (editable mode)
./install-dev.sh --editable

# Or regular local installation
./install-dev.sh

# Or use Python directly
python3 install.py --local-install
```

**Development Installation Options:**
```sh
# Editable installation (changes reflected immediately)
./install-dev.sh --editable

# CPU-only development installation
./install-dev.sh --cpu-only

# See what would be installed
./install-dev.sh --dry-run

# Skip native dependencies (if already installed)
./install-dev.sh --skip-native
```

**Cross-Platform Python Script:**
```sh
# For development from current directory
python3 install.py --local-install

# For production installation from PyPI (when available)
python3 install.py
```

**Installation Options:**
```sh
# See what would be installed (dry run)
./quick-install.sh --dry-run

# CPU-only installation
./quick-install.sh --cpu-only

# Force reinstallation
./quick-install.sh --force-reinstall

# Skip native dependencies (if already installed)
./quick-install.sh --skip-native

# Show all options
./quick-install.sh --help
```

### üîß Manual Installation

If you prefer manual installation or the automated script doesn't work on your system:

**1. Install pipx:**
```sh
# Linux/macOS
python3 -m pip install --user pipx
python3 -m pipx ensurepath

# Windows
python3 -m pip install --user pipx
python3 -m pipx ensurepath
```

**2. Install INTV Package:**
```sh
# Base Installation (CPU-only, no GPU acceleration)
pipx install intv

# GPU-Accelerated Installation (NVIDIA CUDA)
pipx install "intv[full-cuda]"

# Platform-Specific Installations
pipx install "intv[full-rocm]"      # AMD GPUs (ROCm)
pipx install "intv[full-mps]"       # Apple Silicon (MPS)
pipx install "intv[full-intel]"     # Intel GPUs
pipx install "intv[raspberry-pi]"   # Raspberry Pi / ARM systems
pipx install "intv[full]"           # CPU-only with all features
```

**3. Install Native System Dependencies:**

These are **native system libraries** that provide binary executables and can't be installed through pipx/pip. The automated installer handles these, but for manual installation:

**Linux (Debian/Ubuntu)**:
```sh
sudo apt update && sudo apt install -y tesseract-ocr tesseract-ocr-eng poppler-utils ffmpeg
```

**Linux (RHEL/CentOS/Fedora)**:
```sh
sudo dnf install tesseract poppler-utils ffmpeg
```

**macOS (Homebrew)**:
```sh
brew install tesseract poppler ffmpeg
```

**Windows**:
- **Tesseract-OCR**: [Download installer](https://github.com/tesseract-ocr/tesseract/wiki)
- **Poppler**: [Download binaries](http://blog.alivate.com.au/poppler-utils-windows/), add `bin/` to your PATH
- **FFmpeg**: [Download from official site](https://ffmpeg.org/download.html), add to PATH
- Or use package managers: `choco install tesseract poppler ffmpeg` or `winget install tesseract poppler ffmpeg`

**Why these can't be in pipx:**
- **`tesseract-ocr`**: Native C++ OCR engine with system libraries
- **`poppler-utils`**: Native C++ PDF tools required by `pdf2image` Python package
- **`ffmpeg`**: Native multimedia framework for audio/video processing

### Optional Dependencies

**Audio Processing** (if using audio features):
```sh
# Linux
sudo apt install -y portaudio19-dev

# macOS
brew install portaudio

# Windows: Usually works out of the box
```
*Note: `portaudio` provides native C libraries for real-time audio - Python's `sounddevice` depends on it*

**Cloudflare Tunnel** (handled automatically):
- INTV includes a `cloudflared` binary (`scripts/cloudflared-linux-amd64`)
- No separate installation required - works out of the box
- Automatically detects system-installed `cloudflared` if available
- Falls back to included binary if not found in PATH

### How pipx Handles Dependencies

pipx automatically installs the **Python packages** that interface with these system libraries:

```
System Library ‚Üí Python Package (installed by pipx)
===============================================
tesseract-ocr  ‚Üí pytesseract>=0.3.10
poppler-utils  ‚Üí pdf2image>=1.16.0  
portaudio      ‚Üí sounddevice>=0.4.0
```

**Note:** `cloudflared` is included as a bundled binary (`scripts/cloudflared-linux-amd64`) - no separate installation needed.

The Python packages are just **wrappers** that call the native system binaries, which is why both layers are required.

### Verify Installation

Check that INTV is properly installed:
```sh
intv --version
intv-platform  # Shows recommended installation for your system
```

---

## üöÄ Quick Start

### Command Line Usage

After installation with pipx, INTV commands are available globally:

```sh
# Process a document
intv --file document.pdf --type pdf

# Use CPU-only mode (disables GPU acceleration)
intv --file document.pdf --type pdf --cpu

# Process with custom config
intv --file document.pdf --config custom-config.yaml

# Run the web interface
intv --gui

# Process audio files
intv-audio --file recording.wav --output transcript.txt

# OCR processing
intv-ocr --file scanned-document.pdf --output text-output.txt

# Check system compatibility
intv-platform
```

### Web Interface

Start the web server:
```sh
# Local access only
intv --gui

# With Cloudflare tunnel (public access)
intv --gui --cloudflare
```

- **Local access**: [http://localhost:3773](http://localhost:3773)
- **Cloudflare tunnel**: Public URL shown in terminal output

### Docker Deployment

For containerized deployment, use the provided Docker Compose setup:

```sh
# Clone repository for Docker files
git clone https://github.com/Erebus-Nyx/Intv_App.git
cd Intv_App

# GPU deployment
docker-compose up --build -d

# CPU-only deployment
docker-compose -f docker-compose.cpu.yml up --build -d
```
  ```
- For CPU-only, change the Dockerfile in `docker-compose.yml` to `docker/Dockerfile.cpu`.
- The app will be available at [http://localhost:3773](http://localhost:3773)
- To enable Cloudflare tunnel in Docker, set `USE_CLOUDFLARE_TUNNEL=true` in `.env`.

---

## License
See `LICENSE` for details.

---

## Credits
- Inspired by best practices from open-source LLM, RAG, and document automation projects.

---
