#!/usr/bin/env python3
"""
Complete Audio Pipeline Test - Verify End-to-End Audio Processing

This test verifies:
1. Audio files are processed and passed to RAG
2. RAG generates output 
3. Audio transcriptions are stored in the output directory prior to being passed to RAG
4. Complete pipeline flow: Audio â†’ Transcription â†’ VAD â†’ Diarization â†’ RAG â†’ LLM
"""

import sys
import os
import tempfile
import json
import numpy as np
from pathlib import Path
import shutil
import datetime

# Add the intv directory to the Python path
sys.path.insert(0, '/home/nyx/intv')

def create_test_audio_file():
    """Create a simple test audio file for testing"""
    try:
        import soundfile as sf
        
        # Create a simple test audio signal (sine wave)
        sample_rate = 16000
        duration = 3.0  # 3 seconds
        frequency = 440  # A4 note
        
        # Generate sine wave
        t = np.linspace(0, duration, int(sample_rate * duration), False)
        audio_data = 0.3 * np.sin(2 * np.pi * frequency * t)
        
        # Create temporary audio file
        temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
        sf.write(temp_file.name, audio_data, sample_rate)
        temp_file.close()
        
        print(f"âœ… Created test audio file: {temp_file.name}")
        return temp_file.name
        
    except ImportError:
        print("âŒ soundfile not available - cannot create test audio")
        return None
    except Exception as e:
        print(f"âŒ Failed to create test audio: {e}")
        return None

def test_audio_pipeline_imports():
    """Test that all audio pipeline components can be imported"""
    print("\nğŸ” **Testing Audio Pipeline Imports**")
    
    try:
        from intv.pipeline_orchestrator import PipelineOrchestrator
        print("âœ… PipelineOrchestrator imported successfully")
        
        from intv.audio_transcribe import transcribe_audio_fastwhisper
        print("âœ… Audio transcription module imported")
        
        from intv.audio_vad import detect_voice_activity_pyannote
        print("âœ… VAD module imported")
        
        from intv.audio_diarization import diarize_audio
        print("âœ… Diarization module imported")
        
        from intv.rag import chunk_text, enhanced_query_documents
        print("âœ… RAG modules imported")
        
        return True
        
    except Exception as e:
        print(f"âŒ Import failed: {e}")
        return False

def test_output_directory_structure():
    """Test that output directories are properly created and used"""
    print("\nğŸ” **Testing Output Directory Structure**")
    
    # Create test output directory
    test_output_dir = Path("/tmp/intv_test_output")
    test_output_dir.mkdir(exist_ok=True)
    
    # Create cache directory
    cache_dir = test_output_dir / "cache"
    cache_dir.mkdir(exist_ok=True)
    
    print(f"âœ… Test output directory created: {test_output_dir}")
    print(f"âœ… Cache directory created: {cache_dir}")
    
    return test_output_dir, cache_dir

def test_transcription_storage(audio_file, output_dir):
    """Test that transcriptions are stored in output directory before RAG processing"""
    print("\nğŸ” **Testing Transcription Storage**")
    
    try:
        from intv.audio_transcribe import transcribe_audio_fastwhisper
        
        # Transcribe audio
        print("   ğŸ“ Transcribing audio...")
        segments = transcribe_audio_fastwhisper(
            audio_file,
            return_segments=True,
            config={'audio_sample_rate': 16000}
        )
        
        if not segments:
            print("âŒ No transcription segments returned")
            return False
        
        # Extract transcript
        transcript = " ".join([seg.get('text', '') for seg in segments])
        print(f"   âœ… Transcription completed: {len(transcript)} characters")
        print(f"   ğŸ“„ Transcript preview: {transcript[:100]}...")
        
        # Save transcription to output directory (simulating storage before RAG)
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        transcription_file = output_dir / f"transcription_{timestamp}.json"
        
        transcription_data = {
            'transcript': transcript,
            'segments': segments,
            'metadata': {
                'audio_file': audio_file,
                'timestamp': timestamp,
                'num_segments': len(segments)
            }
        }
        
        with open(transcription_file, 'w', encoding='utf-8') as f:
            json.dump(transcription_data, f, indent=2, ensure_ascii=False)
        
        print(f"   âœ… Transcription saved to: {transcription_file}")
        
        return transcription_file, transcript, segments
        
    except Exception as e:
        print(f"âŒ Transcription storage test failed: {e}")
        return None

def test_rag_processing(transcript, chunks, output_dir):
    """Test RAG processing with audio transcription"""
    print("\nğŸ” **Testing RAG Processing**")
    
    try:
        from intv.rag import enhanced_query_documents
        
        if not chunks:
            print("âŒ No chunks available for RAG processing")
            return False
        
        # Test RAG query
        test_query = "What is the main content of this audio?"
        print(f"   ğŸ” Running RAG query: '{test_query}'")
        
        # Process with RAG
        rag_result = enhanced_query_documents(
            test_query,
            chunks,
            config={'rag_top_k': 3}
        )
        
        if not rag_result:
            print("âŒ RAG processing returned no results")
            return False
        
        print(f"   âœ… RAG processing completed")
        print(f"   ğŸ“Š RAG result type: {type(rag_result)}")
        
        # Save RAG results to output directory
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        rag_file = output_dir / f"rag_results_{timestamp}.json"
        
        rag_data = {
            'query': test_query,
            'result': rag_result,
            'chunks_processed': len(chunks),
            'metadata': {
                'timestamp': timestamp,
                'processing_status': 'completed'
            }
        }
        
        with open(rag_file, 'w', encoding='utf-8') as f:
            json.dump(rag_data, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"   âœ… RAG results saved to: {rag_file}")
        
        return rag_result
        
    except Exception as e:
        print(f"âŒ RAG processing test failed: {e}")
        return None

def test_complete_pipeline(audio_file, output_dir):
    """Test the complete audio pipeline end-to-end"""
    print("\nğŸ” **Testing Complete Audio Pipeline**")
    
    try:
        from intv.pipeline_orchestrator import PipelineOrchestrator
        
        # Initialize pipeline orchestrator
        config = {
            'enable_vad': True,
            'enable_diarization': True,
            'audio_sample_rate': 16000,
            'rag_top_k': 3
        }
        
        orchestrator = PipelineOrchestrator(config=config)
        print("   âœ… Pipeline orchestrator initialized")
        
        # Process audio file with query
        test_query = "Summarize the content of this audio"
        print(f"   ğŸµ Processing audio file: {Path(audio_file).name}")
        print(f"   ğŸ” With query: '{test_query}'")
        
        result = orchestrator.process_audio_file(
            file_path=Path(audio_file),
            query=test_query,
            apply_llm=False  # Skip LLM for this test
        )
        
        if not result.success:
            print(f"âŒ Pipeline processing failed: {result.error_message}")
            return False
        
        print(f"   âœ… Pipeline processing completed successfully")
        
        # Verify pipeline results
        print(f"   ğŸ“„ Transcript length: {len(result.transcript) if result.transcript else 0}")
        print(f"   ğŸ§© Chunks created: {len(result.chunks) if result.chunks else 0}")
        print(f"   ğŸ¯ Segments processed: {len(result.segments) if result.segments else 0}")
        
        # Check metadata
        if result.metadata:
            print(f"   ğŸ“Š VAD enabled: {result.metadata.get('vad_enabled', 'Unknown')}")
            print(f"   ğŸ“Š Diarization enabled: {result.metadata.get('diarization_enabled', 'Unknown')}")
            print(f"   ğŸ“Š Pipeline: {result.metadata.get('audio_processing_pipeline', 'Unknown')}")
        
        # Check RAG results
        if result.rag_result:
            print(f"   âœ… RAG processing completed")
            print(f"   ğŸ“Š RAG result type: {type(result.rag_result)}")
        else:
            print(f"   âš ï¸  No RAG results (may be expected)")
        
        # Save complete pipeline result
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        pipeline_file = output_dir / f"complete_pipeline_{timestamp}.json"
        
        pipeline_data = {
            'success': result.success,
            'input_type': result.input_type.value if hasattr(result.input_type, 'value') else str(result.input_type),
            'transcript': result.transcript,
            'transcript_length': len(result.transcript) if result.transcript else 0,
            'chunks_count': len(result.chunks) if result.chunks else 0,
            'segments_count': len(result.segments) if result.segments else 0,
            'metadata': result.metadata,
            'rag_result_available': result.rag_result is not None,
            'processing_timestamp': timestamp
        }
        
        with open(pipeline_file, 'w', encoding='utf-8') as f:
            json.dump(pipeline_data, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"   âœ… Complete pipeline results saved to: {pipeline_file}")
        
        return result
        
    except Exception as e:
        print(f"âŒ Complete pipeline test failed: {e}")
        import traceback
        print(f"   ğŸ” Error details: {traceback.format_exc()}")
        return None

def main():
    """Run complete audio pipeline verification"""
    print("=" * 80)
    print("ğŸµ **INTV Complete Audio Pipeline Verification**")
    print("=" * 80)
    
    # Test 1: Import verification
    if not test_audio_pipeline_imports():
        print("\nâŒ Import tests failed - cannot proceed")
        return False
    
    # Test 2: Output directory setup
    output_dir, cache_dir = test_output_directory_structure()
    
    # Test 3: Create test audio
    audio_file = create_test_audio_file()
    if not audio_file:
        print("\nâš ï¸  Cannot create test audio - looking for existing audio files...")
        
        # Look for existing audio files
        audio_extensions = ['.wav', '.mp3', '.m4a', '.flac']
        found_files = []
        
        search_paths = ['/home/nyx/intv', '/home/nyx/intv/sample-sources']
        for search_path in search_paths:
            if os.path.exists(search_path):
                for root, dirs, files in os.walk(search_path):
                    for file in files:
                        if any(file.lower().endswith(ext) for ext in audio_extensions):
                            found_files.append(os.path.join(root, file))
        
        if found_files:
            audio_file = found_files[0]
            print(f"âœ… Using existing audio file: {audio_file}")
        else:
            print("âŒ No audio files available for testing")
            return False
    
    try:
        # Test 4: Transcription storage
        transcription_result = test_transcription_storage(audio_file, output_dir)
        if not transcription_result:
            print("\nâŒ Transcription storage test failed")
            return False
        
        transcription_file, transcript, segments = transcription_result
        
        # Test 5: Text chunking for RAG
        print("\nğŸ” **Testing Text Chunking for RAG**")
        try:
            from intv.rag import chunk_text
            chunks = chunk_text(transcript)
            print(f"   âœ… Text chunked into {len(chunks)} pieces")
            print(f"   ğŸ“„ First chunk preview: {chunks[0][:100] if chunks else 'No chunks'}...")
        except Exception as e:
            print(f"âŒ Text chunking failed: {e}")
            chunks = []
        
        # Test 6: RAG processing
        if chunks:
            rag_result = test_rag_processing(transcript, chunks, output_dir)
        else:
            print("\nâš ï¸  Skipping RAG test - no chunks available")
            rag_result = None
        
        # Test 7: Complete pipeline
        pipeline_result = test_complete_pipeline(audio_file, output_dir)
        
        # Summary
        print("\n" + "=" * 80)
        print("ğŸ“Š **VERIFICATION SUMMARY**")
        print("=" * 80)
        
        results = {
            "Imports": "âœ… PASS",
            "Output Directory": "âœ… PASS",
            "Audio File": "âœ… PASS" if audio_file else "âŒ FAIL",
            "Transcription Storage": "âœ… PASS" if transcription_result else "âŒ FAIL",
            "Text Chunking": "âœ… PASS" if chunks else "âŒ FAIL",
            "RAG Processing": "âœ… PASS" if rag_result else "âš ï¸  SKIP",
            "Complete Pipeline": "âœ… PASS" if pipeline_result and pipeline_result.success else "âŒ FAIL"
        }
        
        for test, status in results.items():
            print(f"   {test:20} {status}")
        
        # Key verification points
        print("\nğŸ¯ **KEY VERIFICATION POINTS**")
        print(f"   1. Audio processed and passed to RAG: {'âœ… YES' if rag_result else 'âŒ NO'}")
        print(f"   2. RAG generates output: {'âœ… YES' if rag_result else 'âŒ NO'}")
        print(f"   3. Transcriptions stored before RAG: {'âœ… YES' if transcription_file else 'âŒ NO'}")
        print(f"   4. Complete pipeline flow: {'âœ… YES' if pipeline_result and pipeline_result.success else 'âŒ NO'}")
        
        # Output files created
        print(f"\nğŸ“ **Output Files Created in {output_dir}:**")
        if output_dir.exists():
            for file_path in output_dir.glob("*"):
                file_size = file_path.stat().st_size
                print(f"   ğŸ“„ {file_path.name} ({file_size} bytes)")
        
        success = all([
            transcription_result,
            chunks,
            pipeline_result and pipeline_result.success
        ])
        
        print(f"\n{'ğŸ‰ OVERALL: VERIFICATION SUCCESSFUL' if success else 'âŒ OVERALL: VERIFICATION FAILED'}")
        
        return success
        
    finally:
        # Cleanup
        if audio_file and audio_file.startswith('/tmp'):
            try:
                os.unlink(audio_file)
                print(f"\nğŸ§¹ Cleaned up test audio file: {audio_file}")
            except:
                pass

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
